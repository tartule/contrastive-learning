{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b7a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\lavra\\miniconda3\\envs\\tensorflow\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\lavra\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100dbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "AUTO=tf.data.AUTOTUNE\n",
    "learning_rate = 0.001\n",
    "batch_size = 265\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "\n",
    "\n",
    "\n",
    "# Load the train and test data splits\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Display shapes of train and test datasets\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n",
    "test_dataset=(tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .shuffle(1024)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4ca8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.02),\n",
    "        layers.RandomWidth(0.2),\n",
    "        layers.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272493ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder(backbone=keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
    "    )):\n",
    "    \n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = backbone(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad87d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b87d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd721633",
   "metadata": {},
   "source": [
    "# custum model 1 : sequential\n",
    "vgg like network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8167860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_vgg_block(n_conv_layer,depth,pooling_type):\n",
    "    list_layer=[]\n",
    "    for i in range(n_conv_layer):\n",
    "        list_layer.append(layers.Conv2D(depth,3, activation='relu',padding=\"same\"))\n",
    "    \n",
    "    if pooling_type==\"MaxPooling2D\":\n",
    "        list_layer.append(layers.MaxPooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "    elif pooling_type==\"MeanPooling2D\":\n",
    "        list_layer.append(layers.AveragePooling2D(pool_size=(2, 2),padding=\"valid\"))\n",
    "    else:\n",
    "        raise NotImplementedError(\"pooling \"+pooling_type+\" is not implemented\") \n",
    "    return list_layer\n",
    "    \n",
    "    \n",
    "def get_vgg_backbone(input_shape,hparams):\n",
    "    \"\"\"\n",
    "    hparams : dict with keys block1 .... blockn\n",
    "    \n",
    "    \"\"\"\n",
    "    list_layer=[layers.Input(input_shape)]\n",
    "    blocks=hparams[\"blocks\"]\n",
    "    for i in range(1,len(blocks)+1):\n",
    "        list_layer=list_layer+build_vgg_block(**blocks[f\"block{i}\"])\n",
    "        \n",
    "    list_layer.append(layers.Conv2D(hparams[\"output_dim\"],3, activation='relu',padding=\"same\"))\n",
    "    \n",
    "    if hparams[\"globalPoolingType\"]==\"Mean\":\n",
    "        \n",
    "        list_layer.append(layers.GlobalAveragePooling2D())\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tf.keras.Sequential(list_layer)\n",
    "\n",
    "\n",
    "hparams_vgg={\"output_dim\" :2048,\n",
    "             \"globalPoolingType\":\"Mean\",\n",
    "             \"blocks\": {\"block1\":\n",
    "             {\"n_conv_layer\":3,\n",
    "             \"depth\":64,\n",
    "             \"pooling_type\":\"MaxPooling2D\"},\n",
    "            \n",
    "            \"block2\":\n",
    "             {\"n_conv_layer\":3,\n",
    "             \"depth\":128,\n",
    "             \"pooling_type\":\"MaxPooling2D\"},\n",
    "             \n",
    "             \"block3\":\n",
    "             {\"n_conv_layer\":3,\n",
    "             \"depth\":256,\n",
    "             \"pooling_type\":\"MaxPooling2D\"}}\n",
    "             \n",
    "            \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ad6cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 2048)        4720640   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,640,640\n",
      "Trainable params: 6,640,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_backbone=get_vgg_backbone((32,32,3),hparams_vgg)\n",
    "vgg_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ce1a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"sparse_categorical_accuracy\", patience=3,min_delta=0.01, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26bf1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             6640647   \n",
      " )                                                               \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_9 (InputLayer)      [(None, 32, 32, 3)]       0         |\n",
      "|                                                               |\n",
      "| sequential (Sequential)   (None, 32, 32, 3)         7         |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| normalization (Normalizatio  (None, 32, 32, 3)    7         ||\n",
      "|| n)                                                          ||\n",
      "||                                                             ||\n",
      "|| random_flip (RandomFlip)  (None, 32, 32, 3)       0         ||\n",
      "||                                                             ||\n",
      "|| random_rotation (RandomRota  (None, 32, 32, 3)    0         ||\n",
      "|| tion)                                                       ||\n",
      "||                                                             ||\n",
      "|| random_width (RandomWidth)  (None, 32, 32, 3)     0         ||\n",
      "||                                                             ||\n",
      "|| random_height (RandomHeight  (None, 32, 32, 3)    0         ||\n",
      "|| )                                                           ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| sequential_6 (Sequential)  (None, 2048)             6640640   |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| conv2d_30 (Conv2D)      (None, 32, 32, 64)        1792      ||\n",
      "||                                                             ||\n",
      "|| conv2d_31 (Conv2D)      (None, 32, 32, 64)        36928     ||\n",
      "||                                                             ||\n",
      "|| conv2d_32 (Conv2D)      (None, 32, 32, 64)        36928     ||\n",
      "||                                                             ||\n",
      "|| max_pooling2d_12 (MaxPoolin  (None, 16, 16, 64)   0         ||\n",
      "|| g2D)                                                        ||\n",
      "||                                                             ||\n",
      "|| conv2d_33 (Conv2D)      (None, 16, 16, 128)       73856     ||\n",
      "||                                                             ||\n",
      "|| conv2d_34 (Conv2D)      (None, 16, 16, 128)       147584    ||\n",
      "||                                                             ||\n",
      "|| conv2d_35 (Conv2D)      (None, 16, 16, 128)       147584    ||\n",
      "||                                                             ||\n",
      "|| max_pooling2d_13 (MaxPoolin  (None, 8, 8, 128)    0         ||\n",
      "|| g2D)                                                        ||\n",
      "||                                                             ||\n",
      "|| conv2d_36 (Conv2D)      (None, 8, 8, 256)         295168    ||\n",
      "||                                                             ||\n",
      "|| conv2d_37 (Conv2D)      (None, 8, 8, 256)         590080    ||\n",
      "||                                                             ||\n",
      "|| conv2d_38 (Conv2D)      (None, 8, 8, 256)         590080    ||\n",
      "||                                                             ||\n",
      "|| max_pooling2d_14 (MaxPoolin  (None, 4, 4, 256)    0         ||\n",
      "|| g2D)                                                        ||\n",
      "||                                                             ||\n",
      "|| conv2d_39 (Conv2D)      (None, 4, 4, 2048)        4720640   ||\n",
      "||                                                             ||\n",
      "|| global_average_pooling2d_3   (None, 2048)         0         ||\n",
      "|| (GlobalAveragePooling2D)                                    ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " dropout_6 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,694,865\n",
      "Trainable params: 7,694,858\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 52s 246ms/step - loss: 2.0342 - sparse_categorical_accuracy: 0.2150 - val_loss: 1.9974 - val_sparse_categorical_accuracy: 0.2558\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 45s 237ms/step - loss: 1.6567 - sparse_categorical_accuracy: 0.3652 - val_loss: 1.4642 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 45s 237ms/step - loss: 1.4164 - sparse_categorical_accuracy: 0.4752 - val_loss: 1.4335 - val_sparse_categorical_accuracy: 0.4793\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 45s 239ms/step - loss: 1.2326 - sparse_categorical_accuracy: 0.5535 - val_loss: 1.0549 - val_sparse_categorical_accuracy: 0.6290\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 45s 236ms/step - loss: 1.0672 - sparse_categorical_accuracy: 0.6238 - val_loss: 0.9879 - val_sparse_categorical_accuracy: 0.6570\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 44s 230ms/step - loss: 0.9378 - sparse_categorical_accuracy: 0.6733 - val_loss: 0.8822 - val_sparse_categorical_accuracy: 0.6908\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 45s 236ms/step - loss: 0.8473 - sparse_categorical_accuracy: 0.7090 - val_loss: 0.8548 - val_sparse_categorical_accuracy: 0.7039\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 46s 243ms/step - loss: 0.7857 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.7344 - val_sparse_categorical_accuracy: 0.7488\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 44s 234ms/step - loss: 0.7140 - sparse_categorical_accuracy: 0.7567 - val_loss: 0.7498 - val_sparse_categorical_accuracy: 0.7452\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 44s 231ms/step - loss: 0.6746 - sparse_categorical_accuracy: 0.7705 - val_loss: 0.7359 - val_sparse_categorical_accuracy: 0.7552\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 44s 234ms/step - loss: 0.6372 - sparse_categorical_accuracy: 0.7840 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.7779\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 44s 230ms/step - loss: 0.6030 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.7820\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 45s 236ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.7686\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 44s 233ms/step - loss: 0.5543 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.7912\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 45s 238ms/step - loss: 0.5283 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.6088 - val_sparse_categorical_accuracy: 0.7969\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 44s 235ms/step - loss: 0.5094 - sparse_categorical_accuracy: 0.8275 - val_loss: 0.5087 - val_sparse_categorical_accuracy: 0.8324\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 45s 237ms/step - loss: 0.4950 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.5435 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 44s 231ms/step - loss: 0.4731 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.8216\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 42s 224ms/step - loss: 0.4528 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.5638 - val_sparse_categorical_accuracy: 0.8186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "189/189 [==============================] - 44s 232ms/step - loss: 0.4419 - sparse_categorical_accuracy: 0.8493 - val_loss: 0.5331 - val_sparse_categorical_accuracy: 0.8316\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 43s 229ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8543 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 45s 237ms/step - loss: 0.4121 - sparse_categorical_accuracy: 0.8600 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8285\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 43s 228ms/step - loss: 0.4032 - sparse_categorical_accuracy: 0.8624 - val_loss: 0.5632 - val_sparse_categorical_accuracy: 0.8195\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 43s 228ms/step - loss: 0.3956 - sparse_categorical_accuracy: 0.8656 - val_loss: 0.5479 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 44s 234ms/step - loss: 0.3875 - sparse_categorical_accuracy: 0.8676 - val_loss: 0.4828 - val_sparse_categorical_accuracy: 0.8442\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 44s 232ms/step - loss: 0.3674 - sparse_categorical_accuracy: 0.8738 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8453\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 44s 231ms/step - loss: 0.3727 - sparse_categorical_accuracy: 0.8734 - val_loss: 0.5018 - val_sparse_categorical_accuracy: 0.8404\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.8200\n",
      "Test accuracy: 82.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vgg_backbone=get_vgg_backbone((32,32,3),hparams_vgg)\n",
    "\n",
    "encoder = create_encoder(vgg_backbone)\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary(expand_nested=True)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "777433db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             6640647   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,902,919\n",
      "Trainable params: 6,902,912\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 46s 216ms/step - loss: 5.5656\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 40s 210ms/step - loss: 5.3884\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 41s 215ms/step - loss: 5.3238\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 40s 212ms/step - loss: 5.2975\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 39s 207ms/step - loss: 5.2338\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 40s 211ms/step - loss: 5.1855\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 39s 207ms/step - loss: 5.1217\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 41s 215ms/step - loss: 5.0572\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 40s 214ms/step - loss: 4.9923\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 40s 212ms/step - loss: 4.9114\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 40s 209ms/step - loss: 4.8314\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 40s 214ms/step - loss: 4.7496\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 40s 212ms/step - loss: 4.6636\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 40s 211ms/step - loss: 4.5791\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 41s 216ms/step - loss: 4.5172\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 39s 208ms/step - loss: 4.4454\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 40s 210ms/step - loss: 4.3864\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 40s 210ms/step - loss: 4.3373\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 39s 206ms/step - loss: 4.2879\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 39s 206ms/step - loss: 4.2349\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 40s 212ms/step - loss: 4.2065\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 39s 206ms/step - loss: 4.1690\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 40s 212ms/step - loss: 4.1347\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 40s 211ms/step - loss: 4.0972\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 40s 211ms/step - loss: 4.0833\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 39s 207ms/step - loss: 4.0454\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 39s 205ms/step - loss: 4.0283\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 40s 214ms/step - loss: 3.9995\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 39s 207ms/step - loss: 3.9748\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 40s 209ms/step - loss: 3.9567\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 40s 210ms/step - loss: 3.9318\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 39s 206ms/step - loss: 3.9234\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 40s 212ms/step - loss: 3.8983\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 39s 208ms/step - loss: 3.8899\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 39s 208ms/step - loss: 3.8712\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 40s 211ms/step - loss: 3.8470\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 40s 209ms/step - loss: 3.8416\n",
      "Epoch 38/50\n",
      "189/189 [==============================] - 39s 206ms/step - loss: 3.8117\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 40s 213ms/step - loss: 3.8052\n",
      "Epoch 40/50\n",
      "189/189 [==============================] - 39s 205ms/step - loss: 3.7865\n",
      "Epoch 41/50\n",
      "189/189 [==============================] - 40s 210ms/step - loss: 3.7817\n",
      "Epoch 42/50\n",
      "189/189 [==============================] - 40s 214ms/step - loss: 3.7650\n",
      "Epoch 43/50\n",
      "189/189 [==============================] - 40s 211ms/step - loss: 3.7565\n",
      "Epoch 44/50\n",
      "189/189 [==============================] - 39s 208ms/step - loss: 3.7620\n"
     ]
    }
   ],
   "source": [
    "early_stop_unsup=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=1, restore_best_weights=True\n",
    ")\n",
    "vgg_backbone=get_vgg_backbone((32,32,3),hparams_vgg)\n",
    "\n",
    "encoder = create_encoder(vgg_backbone)\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(\n",
    "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop_unsup]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80e14c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "189/189 [==============================] - 26s 113ms/step - loss: 22.0407 - sparse_categorical_accuracy: 0.8704 - val_loss: 4.1563 - val_sparse_categorical_accuracy: 0.8232\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 20s 107ms/step - loss: 2.1677 - sparse_categorical_accuracy: 0.8364 - val_loss: 1.1165 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 20s 107ms/step - loss: 1.0357 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.8264 - val_sparse_categorical_accuracy: 0.8283\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 0.8383 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.8410 - val_sparse_categorical_accuracy: 0.8382\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 4.1563 - sparse_categorical_accuracy: 0.8232\n",
      "Test accuracy: 82.32%\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9e37946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "189/189 [==============================] - 26s 112ms/step - loss: 20.6666 - sparse_categorical_accuracy: 0.8707 - val_loss: 3.3401 - val_sparse_categorical_accuracy: 0.8064\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 2.1886 - sparse_categorical_accuracy: 0.8407 - val_loss: 1.4705 - val_sparse_categorical_accuracy: 0.7967\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 1.0960 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.9608 - val_sparse_categorical_accuracy: 0.8257\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 20s 107ms/step - loss: 0.8125 - sparse_categorical_accuracy: 0.8336 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.8172\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 0.7190 - sparse_categorical_accuracy: 0.8374 - val_loss: 0.7408 - val_sparse_categorical_accuracy: 0.8340\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 0.6781 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.7486 - val_sparse_categorical_accuracy: 0.8301\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 20s 106ms/step - loss: 0.6346 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.7472 - val_sparse_categorical_accuracy: 0.8325\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 0.6130 - sparse_categorical_accuracy: 0.8496 - val_loss: 0.7124 - val_sparse_categorical_accuracy: 0.8298\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 20s 108ms/step - loss: 0.6008 - sparse_categorical_accuracy: 0.8489 - val_loss: 0.7479 - val_sparse_categorical_accuracy: 0.8377\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.7472 - sparse_categorical_accuracy: 0.8325\n",
      "Test accuracy: 83.25%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=2,min_delta=0.05, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883346ad",
   "metadata": {},
   "source": [
    "## model with loss = crossentropyloss+contrastive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459ec61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "189/189 [==============================] - 152s 773ms/step - class_loss: 2.1610 - con_loss: 5.4764 - accuracy: 0.1529 - loss_regu: 0.0000e+00 - val_accuracy: 0.2324\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 136s 724ms/step - class_loss: 1.8766 - con_loss: 5.2961 - accuracy: 0.2552 - loss_regu: 0.0000e+00 - val_accuracy: 0.3150\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 128s 677ms/step - class_loss: 1.6029 - con_loss: 5.1542 - accuracy: 0.3834 - loss_regu: 0.0000e+00 - val_accuracy: 0.5172\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 117s 623ms/step - class_loss: 1.3763 - con_loss: 5.0066 - accuracy: 0.4890 - loss_regu: 0.0000e+00 - val_accuracy: 0.5730\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 107s 566ms/step - class_loss: 1.1945 - con_loss: 4.8598 - accuracy: 0.5598 - loss_regu: 0.0000e+00 - val_accuracy: 0.6102\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 103s 547ms/step - class_loss: 1.0355 - con_loss: 4.7187 - accuracy: 0.6292 - loss_regu: 0.0000e+00 - val_accuracy: 0.6544\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 100s 532ms/step - class_loss: 0.9286 - con_loss: 4.6107 - accuracy: 0.6685 - loss_regu: 0.0000e+00 - val_accuracy: 0.6981\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 99s 527ms/step - class_loss: 0.8507 - con_loss: 4.5296 - accuracy: 0.6989 - loss_regu: 0.0000e+00 - val_accuracy: 0.7144\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 96s 509ms/step - class_loss: 0.7606 - con_loss: 4.4199 - accuracy: 0.7371 - loss_regu: 0.0000e+00 - val_accuracy: 0.7438\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 101s 536ms/step - class_loss: 0.7098 - con_loss: 4.3681 - accuracy: 0.7570 - loss_regu: 0.0000e+00 - val_accuracy: 0.7692\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 99s 527ms/step - class_loss: 0.6605 - con_loss: 4.3056 - accuracy: 0.7745 - loss_regu: 0.0000e+00 - val_accuracy: 0.7641\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 98s 519ms/step - class_loss: 0.6246 - con_loss: 4.2651 - accuracy: 0.7883 - loss_regu: 0.0000e+00 - val_accuracy: 0.7736\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 99s 523ms/step - class_loss: 0.5757 - con_loss: 4.2005 - accuracy: 0.8057 - loss_regu: 0.0000e+00 - val_accuracy: 0.7864\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 79s 420ms/step - class_loss: 0.5560 - con_loss: 4.1750 - accuracy: 0.8120 - loss_regu: 0.0000e+00 - val_accuracy: 0.8083\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 97s 513ms/step - class_loss: 0.5249 - con_loss: 4.1309 - accuracy: 0.8222 - loss_regu: 0.0000e+00 - val_accuracy: 0.8078\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 107s 567ms/step - class_loss: 0.5104 - con_loss: 4.1171 - accuracy: 0.8259 - loss_regu: 0.0000e+00 - val_accuracy: 0.8074\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 109s 581ms/step - class_loss: 0.4831 - con_loss: 4.0829 - accuracy: 0.8364 - loss_regu: 0.0000e+00 - val_accuracy: 0.8036\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 99s 523ms/step - class_loss: 0.4765 - con_loss: 4.0716 - accuracy: 0.8415 - loss_regu: 0.0000e+00 - val_accuracy: 0.8091\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 63s 332ms/step - class_loss: 0.4637 - con_loss: 4.0529 - accuracy: 0.8433 - loss_regu: 0.0000e+00 - val_accuracy: 0.8017\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 61s 323ms/step - class_loss: 0.4387 - con_loss: 4.0150 - accuracy: 0.8487 - loss_regu: 0.0000e+00 - val_accuracy: 0.8182\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 62s 327ms/step - class_loss: 0.4363 - con_loss: 4.0059 - accuracy: 0.8514 - loss_regu: 0.0000e+00 - val_accuracy: 0.8329\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 60s 320ms/step - class_loss: 0.4004 - con_loss: 3.9636 - accuracy: 0.8638 - loss_regu: 0.0000e+00 - val_accuracy: 0.8374\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 63s 332ms/step - class_loss: 0.4010 - con_loss: 3.9572 - accuracy: 0.8661 - loss_regu: 0.0000e+00 - val_accuracy: 0.8386\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 62s 326ms/step - class_loss: 0.3854 - con_loss: 3.9373 - accuracy: 0.8710 - loss_regu: 0.0000e+00 - val_accuracy: 0.8438\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 63s 333ms/step - class_loss: 0.3702 - con_loss: 3.9129 - accuracy: 0.8756 - loss_regu: 0.0000e+00 - val_accuracy: 0.8409\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 61s 325ms/step - class_loss: 0.3622 - con_loss: 3.8948 - accuracy: 0.8786 - loss_regu: 0.0000e+00 - val_accuracy: 0.8495\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 62s 328ms/step - class_loss: 0.3575 - con_loss: 3.8935 - accuracy: 0.8807 - loss_regu: 0.0000e+00 - val_accuracy: 0.8511\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 62s 327ms/step - class_loss: 0.3404 - con_loss: 3.8658 - accuracy: 0.8850 - loss_regu: 0.0000e+00 - val_accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "class partial_contrastive_model(tf.keras.Model):\n",
    "    def __init__(self, backbone):\n",
    "        super(partial_contrastive_model, self).__init__()\n",
    "        \n",
    "        self.backbone=backbone\n",
    "        self.classification=tf.keras.Sequential([\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(hidden_units, activation=\"relu\"),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.projection=layers.Dense(projection_units, activation=\"relu\")\n",
    "        self.loss_contrastive_fn=SupervisedContrastiveLoss(temperature)\n",
    "        self.loss_classification_fn=keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        self.loss_class_tracker = tf.keras.metrics.Mean(name=\"loss_classification\")\n",
    "        self.loss_contr_tracker=tf.keras.metrics.Mean(name=\"loss_contrastive\")\n",
    "        self.loss_regu_tracker=tf.keras.metrics.Mean(name=\"loss_regu\")\n",
    "        \n",
    "        self.accuracy_tracker=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.val_accuracy_tracker=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_class_tracker,\n",
    "                self.loss_contr_tracker,\n",
    "                self.loss_regu_tracker,\n",
    "                self.accuracy_tracker,\n",
    "               self.val_accuracy_tracker]\n",
    "        \n",
    "    def call(self,inputs,training=False):\n",
    "        \n",
    "        embedding=self.backbone(inputs,training=training)\n",
    "    \n",
    "        return self.classification(embedding,training=training)\n",
    "    \n",
    "    def train_step(self, inputs):\n",
    "        \n",
    "        images,labels=inputs\n",
    "        \n",
    "        \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            embedding=self.backbone(images,training=True)\n",
    "            class_pred=self.classification(embedding,training=True)\n",
    "            projection_embeding=self.projection(embedding,training=True)\n",
    "            con_loss=self.loss_contrastive_fn(labels,projection_embeding)\n",
    "            class_loss=self.loss_classification_fn(labels,class_pred)\n",
    "            regu_loss=sum(self.losses)\n",
    "            loss=(con_loss+class_loss)/2+regu_loss\n",
    "            \n",
    "        \n",
    "        learnable_params = (\n",
    "            self.backbone.trainable_variables+self.classification.trainable_variables + self.projection.trainable_variables\n",
    "        )\n",
    "        \n",
    "        gradients = tape.gradient(loss, learnable_params)\n",
    "        self.optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "        self.loss_class_tracker.update_state(class_loss)\n",
    "        self.loss_contr_tracker.update_state(con_loss)\n",
    "        self.loss_regu_tracker.update_state(regu_loss)\n",
    "        self.accuracy_tracker.update_state(labels,class_pred)\n",
    "\n",
    "        return {\"class_loss\": self.loss_class_tracker.result(),\n",
    "                \"con_loss\":self.loss_contr_tracker.result(),\n",
    "                \"accuracy\":self.accuracy_tracker.result(),\n",
    "                \"loss_regu\":self.loss_regu_tracker.result()}\n",
    "    \n",
    "    def test_step(self,inputs):\n",
    "        \n",
    "        \n",
    "        images,labels=inputs\n",
    "        class_pred=self(images,training=False)\n",
    "        self.val_accuracy_tracker.update_state(labels,class_pred)\n",
    "        \n",
    "        return {\"accuracy\":self.val_accuracy_tracker.result()}\n",
    "\n",
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "monitor=\"con_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "    \n",
    "vgg_backbone=get_vgg_backbone((32,32,3),hparams_vgg)\n",
    "\n",
    "inputs=layers.Input((32,32,3))\n",
    "x=data_augmentation(inputs)\n",
    "x=vgg_backbone(x)\n",
    "vgg_backbone_with_data_aug=tf.keras.Model(inputs,x)\n",
    "model=partial_contrastive_model(vgg_backbone_with_data_aug)  \n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate)\n",
    ")\n",
    "\n",
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "monitor=\"con_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "history = model.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d04dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "189/189 [==============================] - 63s 320ms/step - class_loss: 0.3632 - con_loss: 3.9051 - accuracy: 0.8750 - loss_regu: 0.0000e+00 - val_accuracy: 0.8427\n",
      "Epoch 2/22\n",
      "189/189 [==============================] - 61s 326ms/step - class_loss: 0.3663 - con_loss: 3.9046 - accuracy: 0.8786 - loss_regu: 0.0000e+00 - val_accuracy: 0.8414\n",
      "Epoch 3/22\n",
      "189/189 [==============================] - 62s 328ms/step - class_loss: 0.3379 - con_loss: 3.8637 - accuracy: 0.8857 - loss_regu: 0.0000e+00 - val_accuracy: 0.8347\n",
      "Epoch 4/22\n",
      "189/189 [==============================] - 61s 323ms/step - class_loss: 0.3351 - con_loss: 3.8594 - accuracy: 0.8876 - loss_regu: 0.0000e+00 - val_accuracy: 0.8487\n",
      "Epoch 5/22\n",
      "189/189 [==============================] - 63s 333ms/step - class_loss: 0.3291 - con_loss: 3.8501 - accuracy: 0.8880 - loss_regu: 0.0000e+00 - val_accuracy: 0.8477\n",
      "Epoch 6/22\n",
      "189/189 [==============================] - 61s 323ms/step - class_loss: 0.3213 - con_loss: 3.8339 - accuracy: 0.8924 - loss_regu: 0.0000e+00 - val_accuracy: 0.8363\n",
      "Epoch 7/22\n",
      "189/189 [==============================] - 61s 323ms/step - class_loss: 0.3043 - con_loss: 3.8100 - accuracy: 0.8982 - loss_regu: 0.0000e+00 - val_accuracy: 0.8540\n",
      "Epoch 8/22\n",
      "189/189 [==============================] - 62s 331ms/step - class_loss: 0.2987 - con_loss: 3.8105 - accuracy: 0.8971 - loss_regu: 0.0000e+00 - val_accuracy: 0.8366\n",
      "Epoch 9/22\n",
      "189/189 [==============================] - 62s 330ms/step - class_loss: 0.3027 - con_loss: 3.8045 - accuracy: 0.8966 - loss_regu: 0.0000e+00 - val_accuracy: 0.8514\n",
      "Epoch 10/22\n",
      "189/189 [==============================] - 62s 329ms/step - class_loss: 0.3056 - con_loss: 3.8126 - accuracy: 0.8960 - loss_regu: 0.0000e+00 - val_accuracy: 0.8513\n",
      "Epoch 11/22\n",
      "189/189 [==============================] - 62s 327ms/step - class_loss: 0.2905 - con_loss: 3.7837 - accuracy: 0.9017 - loss_regu: 0.0000e+00 - val_accuracy: 0.8498\n",
      "Epoch 12/22\n",
      "189/189 [==============================] - 62s 326ms/step - class_loss: 0.2939 - con_loss: 3.7877 - accuracy: 0.9007 - loss_regu: 0.0000e+00 - val_accuracy: 0.8561\n",
      "Epoch 13/22\n",
      "189/189 [==============================] - 60s 317ms/step - class_loss: 0.2729 - con_loss: 3.7528 - accuracy: 0.9085 - loss_regu: 0.0000e+00 - val_accuracy: 0.8547\n",
      "Epoch 14/22\n",
      "189/189 [==============================] - 63s 336ms/step - class_loss: 0.2658 - con_loss: 3.7437 - accuracy: 0.9106 - loss_regu: 0.0000e+00 - val_accuracy: 0.8559\n",
      "Epoch 15/22\n",
      "189/189 [==============================] - 61s 324ms/step - class_loss: 0.2700 - con_loss: 3.7544 - accuracy: 0.9084 - loss_regu: 0.0000e+00 - val_accuracy: 0.8619\n",
      "Epoch 16/22\n",
      "189/189 [==============================] - 60s 320ms/step - class_loss: 0.2648 - con_loss: 3.7420 - accuracy: 0.9093 - loss_regu: 0.0000e+00 - val_accuracy: 0.8463\n",
      "Epoch 17/22\n",
      "189/189 [==============================] - 60s 320ms/step - class_loss: 0.2630 - con_loss: 3.7347 - accuracy: 0.9119 - loss_regu: 0.0000e+00 - val_accuracy: 0.8536\n",
      "Epoch 18/22\n",
      "189/189 [==============================] - 62s 329ms/step - class_loss: 0.2523 - con_loss: 3.7214 - accuracy: 0.9129 - loss_regu: 0.0000e+00 - val_accuracy: 0.8685\n",
      "Epoch 19/22\n",
      "189/189 [==============================] - 62s 329ms/step - class_loss: 0.2477 - con_loss: 3.7183 - accuracy: 0.9164 - loss_regu: 0.0000e+00 - val_accuracy: 0.8695\n",
      "Epoch 20/22\n",
      "189/189 [==============================] - 61s 322ms/step - class_loss: 0.2350 - con_loss: 3.6894 - accuracy: 0.9203 - loss_regu: 0.0000e+00 - val_accuracy: 0.8676\n",
      "Epoch 21/22\n",
      "189/189 [==============================] - 62s 329ms/step - class_loss: 0.2360 - con_loss: 3.6896 - accuracy: 0.9212 - loss_regu: 0.0000e+00 - val_accuracy: 0.8619\n",
      "Epoch 22/22\n",
      "189/189 [==============================] - 60s 320ms/step - class_loss: 0.2333 - con_loss: 3.6812 - accuracy: 0.9226 - loss_regu: 0.0000e+00 - val_accuracy: 0.8460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "monitor=\"con_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "history = model.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=22,callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2215aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 16s 13ms/step - accuracy: 0.8468\n",
      "Test accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20bdeba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 16s 13ms/step - accuracy: 0.8468\n",
      "Test accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7065907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 24s 64ms/step - accuracy: 0.8470\n",
      "Test accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20ebf64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 23s 64ms/step - accuracy: 0.8429\n",
      "Test accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a40a81",
   "metadata": {},
   "source": [
    "## custum model 2 : 1 training step = training step contrastive, then training step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d83bd513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "189/189 [==============================] - 93s 437ms/step - class_loss: 2.2464 - con_loss: 5.5095 - accuracy: 0.1467 - val_accuracy: 0.2712\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 82s 432ms/step - class_loss: 1.7627 - con_loss: 5.2540 - accuracy: 0.3110 - val_accuracy: 0.4365\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 82s 434ms/step - class_loss: 1.4130 - con_loss: 5.0293 - accuracy: 0.4644 - val_accuracy: 0.5976\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 81s 427ms/step - class_loss: 1.1328 - con_loss: 4.8127 - accuracy: 0.5859 - val_accuracy: 0.6669\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 81s 429ms/step - class_loss: 0.9408 - con_loss: 4.6319 - accuracy: 0.6631 - val_accuracy: 0.6686\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 81s 428ms/step - class_loss: 0.8031 - con_loss: 4.4801 - accuracy: 0.7195 - val_accuracy: 0.7062\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 82s 433ms/step - class_loss: 0.7125 - con_loss: 4.3998 - accuracy: 0.7584 - val_accuracy: 0.7353\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 82s 432ms/step - class_loss: 0.6232 - con_loss: 4.2873 - accuracy: 0.7888 - val_accuracy: 0.7724\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 82s 432ms/step - class_loss: 0.5724 - con_loss: 4.2292 - accuracy: 0.8086 - val_accuracy: 0.7968\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 82s 435ms/step - class_loss: 0.5393 - con_loss: 4.1677 - accuracy: 0.8196 - val_accuracy: 0.7881\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 82s 432ms/step - class_loss: 0.4987 - con_loss: 4.1170 - accuracy: 0.8332 - val_accuracy: 0.8022\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 82s 433ms/step - class_loss: 0.4712 - con_loss: 4.0787 - accuracy: 0.8438 - val_accuracy: 0.8088\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 82s 435ms/step - class_loss: 0.4465 - con_loss: 4.0384 - accuracy: 0.8518 - val_accuracy: 0.8308\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 82s 433ms/step - class_loss: 0.4197 - con_loss: 4.0065 - accuracy: 0.8606 - val_accuracy: 0.8420\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 82s 435ms/step - class_loss: 0.3919 - con_loss: 3.9856 - accuracy: 0.8684 - val_accuracy: 0.8388\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 82s 436ms/step - class_loss: 0.3797 - con_loss: 3.9436 - accuracy: 0.8732 - val_accuracy: 0.8481\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 82s 435ms/step - class_loss: 0.3653 - con_loss: 3.9355 - accuracy: 0.8794 - val_accuracy: 0.8421\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 82s 434ms/step - class_loss: 0.3462 - con_loss: 3.9012 - accuracy: 0.8828 - val_accuracy: 0.8485\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 80s 425ms/step - class_loss: 0.3460 - con_loss: 3.8848 - accuracy: 0.8857 - val_accuracy: 0.8424\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 84s 443ms/step - class_loss: 0.3236 - con_loss: 3.8457 - accuracy: 0.8931 - val_accuracy: 0.8534\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 82s 433ms/step - class_loss: 0.3185 - con_loss: 3.8248 - accuracy: 0.8964 - val_accuracy: 0.8570\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 82s 436ms/step - class_loss: 0.2993 - con_loss: 3.8118 - accuracy: 0.9005 - val_accuracy: 0.8512\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 82s 436ms/step - class_loss: 0.2939 - con_loss: 3.8096 - accuracy: 0.9009 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "class partial_contrastive_model2(tf.keras.Model):\n",
    "    def __init__(self, backbone):\n",
    "        super(partial_contrastive_model2, self).__init__()\n",
    "        self.backbone=backbone\n",
    "        self.classification=tf.keras.Sequential([\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(hidden_units, activation=\"relu\"),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.projection=layers.Dense(projection_units, activation=\"relu\")\n",
    "        self.loss_contrastive_fn=SupervisedContrastiveLoss(temperature)\n",
    "        self.loss_classification_fn=keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        self.loss_class_tracker = tf.keras.metrics.Mean(name=\"loss_classification\")\n",
    "        self.loss_contr_tracker=tf.keras.metrics.Mean(name=\"loss_contrastive\")\n",
    "        self.accuracy_tracker=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.val_accuracy_tracker=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_class_tracker,\n",
    "                self.loss_contr_tracker,\n",
    "                self.accuracy_tracker,\n",
    "               self.val_accuracy_tracker]\n",
    "        \n",
    "    def call(self,inputs,training=False):\n",
    "        \n",
    "        embedding=self.backbone(inputs,training=training)\n",
    "    \n",
    "        return self.classification(embedding,training=training)\n",
    "    \n",
    "    def train_step(self, inputs):\n",
    "        \n",
    "        images,labels=inputs\n",
    "        \n",
    "        \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            embedding=self.backbone(images,training=True)\n",
    "\n",
    "            projection_embeding=self.projection(embedding,training=True)\n",
    "            con_loss=self.loss_contrastive_fn(labels,projection_embeding)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        learnable_params = (\n",
    "            self.backbone.trainable_variables+ self.projection.trainable_variables\n",
    "        )\n",
    "        \n",
    "        gradients = tape.gradient(con_loss, learnable_params)\n",
    "        self.optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            embedding=self.backbone(images,training=True)\n",
    "            class_pred=self.classification(embedding,training=True)\n",
    "           \n",
    "            class_loss=self.loss_classification_fn(labels,class_pred)\n",
    "           \n",
    "\n",
    "\n",
    "        \n",
    "        learnable_params = (\n",
    "            self.backbone.trainable_variables+self.classification.trainable_variables\n",
    "        )\n",
    "        \n",
    "        gradients = tape.gradient(class_loss, learnable_params)\n",
    "        self.optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.loss_class_tracker.update_state(class_loss)\n",
    "        self.loss_contr_tracker.update_state(con_loss)\n",
    "        \n",
    "        self.accuracy_tracker.update_state(labels,class_pred)\n",
    "\n",
    "        return {\"class_loss\": self.loss_class_tracker.result(),\n",
    "                \"con_loss\":self.loss_contr_tracker.result(),\n",
    "                \"accuracy\":self.accuracy_tracker.result()}\n",
    "    def test_step(self,inputs):\n",
    "        \n",
    "        \n",
    "        images,labels=inputs\n",
    "        \n",
    "        class_pred=self(images,training=False)\n",
    "        \n",
    "        self.val_accuracy_tracker.update_state(labels,class_pred)\n",
    "\n",
    "        return {\"accuracy\":self.val_accuracy_tracker.result()}\n",
    "\n",
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "monitor=\"accuracy\", patience=3,min_delta=0.01, restore_best_weights=True\n",
    ")\n",
    "vgg_backbone=get_vgg_backbone((32,32,3),hparams_vgg)\n",
    "\n",
    "    \n",
    "inputs=layers.Input((32,32,3))\n",
    "x=data_augmentation(inputs)\n",
    "x=vgg_backbone(x)\n",
    "vgg_backbone_with_data_aug=tf.keras.Model(inputs,x)\n",
    "model=partial_contrastive_model2(vgg_backbone_with_data_aug)  \n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate)\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adb45dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 17ms/step - accuracy: 0.8530\n",
      "Test accuracy: 85.34%\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5e4164173e5f76c814705fb28e6cc0acbaf98ee4506b285c7da95add4000027"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
