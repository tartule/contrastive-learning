{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b7a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\lavra\\miniconda3\\envs\\tensorflow\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\lavra\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100dbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "AUTO=tf.data.AUTOTUNE\n",
    "learning_rate = 0.001\n",
    "batch_size = 265\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "\n",
    "\n",
    "\n",
    "# Load the train and test data splits\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Display shapes of train and test datasets\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n",
    "test_dataset=(tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .shuffle(1024)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4ca8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.02),\n",
    "        layers.RandomWidth(0.2),\n",
    "        layers.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272493ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder(backbone=keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
    "    )):\n",
    "    \n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = backbone(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad87d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b87d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95fd8c",
   "metadata": {},
   "source": [
    "## model definition with the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8919d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 64)   9472        ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 16, 16, 64)  0           ['conv2d_12[0][0]',              \n",
      " mbda)                                                            'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 16, 16, 64)   0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 16, 16, 64)  0           ['re_lu_4[0][0]',                \n",
      " mbda)                                                            'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 16, 16, 64)   0           ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 16, 16, 64)  0           ['re_lu_5[0][0]',                \n",
      " mbda)                                                            'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 16, 16, 64)   0           ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 128)    73856       ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 128)    8320        ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 8, 8, 128)   0           ['conv2d_19[0][0]',              \n",
      " mbda)                                                            'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 8, 8, 128)    0           ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 256)    295168      ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 4, 4, 256)    33024       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 4, 256)    590080      ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 4, 4, 256)   0           ['conv2d_22[0][0]',              \n",
      " mbda)                                                            'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 4, 4, 256)    0           ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 4, 4, 2048)   4720640     ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['conv2d_25[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,099,712\n",
      "Trainable params: 6,099,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def apply_resnet_block(x,downsample,conv_by_block):\n",
    "    \n",
    "    depth_input=x.shape[-1]\n",
    "    \n",
    "    \n",
    "    if downsample:\n",
    "        depth=depth_input*2\n",
    "        skiped=layers.Conv2D(depth,1,strides=(2,2),activation=None)(x)#linear projection\n",
    "        x=layers.Conv2D(depth,3,strides=(2,2), activation='relu',padding=\"same\")(x)\n",
    "    else:\n",
    "        depth=depth_input\n",
    "        skiped=x\n",
    "        x=layers.Conv2D(depth,3, activation='relu',padding=\"same\")(x)\n",
    "        \n",
    "    for i in range(1,conv_by_block-1):\n",
    "        x=layers.Conv2D(depth,3, activation='relu',padding=\"same\")(x)\n",
    "    \n",
    "    x=layers.Conv2D(depth,3,padding=\"same\")(x)\n",
    "         \n",
    "    x=skiped+x\n",
    "    x=layers.ReLU()(x)\n",
    "   \n",
    "    return x\n",
    "\n",
    "def get_resnet_backbone(input_shape,hparams):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    assert hparams[\"conv_by_block\"]>=2\n",
    "    inputs=layers.Input((32,32,3))\n",
    "    x=layers.Conv2D(hparams[\"depth_first_convolution\"],7,strides=(2,2),activation='relu',padding=\"same\")(inputs)\n",
    "    \n",
    "    for block in range(1,hparams[\"number_of_block\"]+1):\n",
    "        x=apply_resnet_block(x,block in hparams[\"downsample_num\"],hparams[\"conv_by_block\"])\n",
    "       \n",
    "        \n",
    "    x=layers.Conv2D(hparams[\"output_dim\"],3, activation='relu',padding=\"same\")(x)\n",
    "    \n",
    "    if hparams[\"globalPoolingType\"]==\"Mean\":\n",
    "        \n",
    "        x=layers.GlobalAveragePooling2D()(x)\n",
    " \n",
    "    return tf.keras.Model(inputs,x)\n",
    "\n",
    "\n",
    "\n",
    "hparams_resnet={\"depth_first_convolution\":64,\n",
    "                \"output_dim\":2048,\n",
    "                \"number_of_block\":5,\n",
    "                \"downsample_num\":[4,5],\n",
    "                \"conv_by_block\":2,\n",
    "                \"globalPoolingType\":\"Mean\"\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resnet=get_resnet_backbone(input_shape,hparams_resnet)\n",
    "\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04610f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             6099719   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,153,937\n",
      "Trainable params: 7,153,930\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 53s 243ms/step - loss: 1.9358 - sparse_categorical_accuracy: 0.2641 - val_loss: 1.6342 - val_sparse_categorical_accuracy: 0.3769\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 36s 190ms/step - loss: 1.5614 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.3643 - val_sparse_categorical_accuracy: 0.4842\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 34s 182ms/step - loss: 1.3491 - sparse_categorical_accuracy: 0.5100 - val_loss: 1.2563 - val_sparse_categorical_accuracy: 0.5451\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 36s 191ms/step - loss: 1.2059 - sparse_categorical_accuracy: 0.5679 - val_loss: 1.1241 - val_sparse_categorical_accuracy: 0.5980\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 37s 194ms/step - loss: 1.0749 - sparse_categorical_accuracy: 0.6165 - val_loss: 1.0254 - val_sparse_categorical_accuracy: 0.6403\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 0.9856 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.9850 - val_sparse_categorical_accuracy: 0.6593\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 36s 189ms/step - loss: 0.9063 - sparse_categorical_accuracy: 0.6842 - val_loss: 0.9010 - val_sparse_categorical_accuracy: 0.6879\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 0.8490 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.9118 - val_sparse_categorical_accuracy: 0.6983\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 0.8038 - sparse_categorical_accuracy: 0.7218 - val_loss: 0.8392 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 0.7519 - sparse_categorical_accuracy: 0.7381 - val_loss: 0.7825 - val_sparse_categorical_accuracy: 0.7350\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 34s 182ms/step - loss: 0.7154 - sparse_categorical_accuracy: 0.7516 - val_loss: 0.8262 - val_sparse_categorical_accuracy: 0.7215\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 0.6955 - sparse_categorical_accuracy: 0.7606 - val_loss: 0.7381 - val_sparse_categorical_accuracy: 0.7474\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 0.6504 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.7673\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 0.6266 - sparse_categorical_accuracy: 0.7844 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.7610\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 0.6045 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.7672\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 0.5822 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.7739\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 32s 170ms/step - loss: 0.5706 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.7757\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 0.5434 - sparse_categorical_accuracy: 0.8133 - val_loss: 0.7381 - val_sparse_categorical_accuracy: 0.7733\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 0.5293 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.7830\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 0.5094 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.7912\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 34s 182ms/step - loss: 0.5071 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.7928\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 0.4910 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.7869\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 33s 173ms/step - loss: 0.4800 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.6152 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 0.4600 - sparse_categorical_accuracy: 0.8389 - val_loss: 0.6206 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 0.4564 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.7816\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 0.4397 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.6283 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 34s 177ms/step - loss: 0.4270 - sparse_categorical_accuracy: 0.8527 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 0.4156 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.6148 - val_sparse_categorical_accuracy: 0.8117\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 0.4132 - sparse_categorical_accuracy: 0.8560 - val_loss: 0.6253 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 0.4078 - sparse_categorical_accuracy: 0.8582 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 0.3966 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.5774 - val_sparse_categorical_accuracy: 0.8163\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 0.3847 - sparse_categorical_accuracy: 0.8646 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.8132\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 0.3850 - sparse_categorical_accuracy: 0.8667 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.8206\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 33s 174ms/step - loss: 0.3802 - sparse_categorical_accuracy: 0.8669 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.8130\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 0.3706 - sparse_categorical_accuracy: 0.8694 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.8169\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 0.3594 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.8211\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 0.3577 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.6131 - val_sparse_categorical_accuracy: 0.8154\n",
      "Epoch 38/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 0.3464 - sparse_categorical_accuracy: 0.8803 - val_loss: 0.6332 - val_sparse_categorical_accuracy: 0.8139\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 0.3461 - sparse_categorical_accuracy: 0.8786 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 40/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.5949 - val_sparse_categorical_accuracy: 0.8258\n",
      "Epoch 41/50\n",
      "189/189 [==============================] - 34s 177ms/step - loss: 0.3275 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.6374 - val_sparse_categorical_accuracy: 0.8176\n",
      "Epoch 42/50\n",
      "189/189 [==============================] - 32s 171ms/step - loss: 0.3323 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.8198\n",
      "Epoch 43/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 0.3189 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.8132\n",
      "Epoch 44/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 0.3278 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.8164\n",
      "Epoch 45/50\n",
      "189/189 [==============================] - 33s 174ms/step - loss: 0.3102 - sparse_categorical_accuracy: 0.8926 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 46/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 0.3001 - sparse_categorical_accuracy: 0.8942 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.8243\n",
      "Epoch 47/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 0.3049 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.8172\n",
      "Epoch 48/50\n",
      "189/189 [==============================] - 35s 183ms/step - loss: 0.2986 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.6186 - val_sparse_categorical_accuracy: 0.8252\n",
      "Epoch 49/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 0.3028 - sparse_categorical_accuracy: 0.8942 - val_loss: 0.6200 - val_sparse_categorical_accuracy: 0.8272\n",
      "Epoch 50/50\n",
      "189/189 [==============================] - 34s 177ms/step - loss: 0.2930 - sparse_categorical_accuracy: 0.8985 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.8201\n",
      "313/313 [==============================] - 7s 19ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.8201\n",
      "Test accuracy: 82.01%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"sparse_categorical_accuracy\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "encoder = create_encoder(resnet)\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary(expand_nested=False)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0edd4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             6099719   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               262272    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,361,991\n",
      "Trainable params: 6,361,984\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 39s 162ms/step - loss: 5.5790\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 5.4526\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 30s 161ms/step - loss: 5.3456\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 5.3087\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 5.2840\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 5.2405\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 5.1715\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 32s 167ms/step - loss: 5.1332\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 5.0792\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 5.0384\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 4.9919\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 32s 167ms/step - loss: 4.9332\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 31s 166ms/step - loss: 4.8926\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.8328\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.7698\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 30s 161ms/step - loss: 4.7224\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.6715\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.6307\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 4.5790\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 31s 167ms/step - loss: 4.5415\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.5096\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 4.4768\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.4434\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 30s 160ms/step - loss: 4.4293\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.3830\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 31s 163ms/step - loss: 4.3699\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 31s 163ms/step - loss: 4.3391\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.3134\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 30s 160ms/step - loss: 4.3015\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.2685\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 30s 159ms/step - loss: 4.2414\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 31s 163ms/step - loss: 4.2326\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 30s 160ms/step - loss: 4.2053\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.1843\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.1766\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 30s 161ms/step - loss: 4.1555\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 30s 161ms/step - loss: 4.1460\n",
      "Epoch 38/50\n",
      "189/189 [==============================] - 31s 163ms/step - loss: 4.1296\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.1030\n",
      "Epoch 40/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.0975\n",
      "Epoch 41/50\n",
      "189/189 [==============================] - 30s 161ms/step - loss: 4.0784\n",
      "Epoch 42/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.0589\n",
      "Epoch 43/50\n",
      "189/189 [==============================] - 31s 163ms/step - loss: 4.0496\n",
      "Epoch 44/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.0230\n",
      "Epoch 45/50\n",
      "189/189 [==============================] - 31s 162ms/step - loss: 4.0155\n",
      "Epoch 46/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 4.0034\n",
      "Epoch 47/50\n",
      "189/189 [==============================] - 31s 164ms/step - loss: 3.9967\n",
      "Epoch 48/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 3.9764\n",
      "Epoch 49/50\n",
      "189/189 [==============================] - 30s 159ms/step - loss: 3.9700\n",
      "Epoch 50/50\n",
      "189/189 [==============================] - 31s 165ms/step - loss: 3.9610\n"
     ]
    }
   ],
   "source": [
    "early_stop_unsup=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=1, restore_best_weights=True\n",
    ")\n",
    "learning_rate=0.001\n",
    "resnet=get_resnet_backbone(input_shape,hparams_resnet)\n",
    "\n",
    "encoder = create_encoder(resnet)\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(\n",
    "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop_unsup]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06bc6f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 21s 83ms/step - loss: 31.9432 - sparse_categorical_accuracy: 0.7771 - val_loss: 3.4085 - val_sparse_categorical_accuracy: 0.7129\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 2.4891 - sparse_categorical_accuracy: 0.7258 - val_loss: 1.4883 - val_sparse_categorical_accuracy: 0.7265\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 15s 78ms/step - loss: 1.3891 - sparse_categorical_accuracy: 0.7159 - val_loss: 1.2755 - val_sparse_categorical_accuracy: 0.7332\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 1.1902 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.1133 - val_sparse_categorical_accuracy: 0.7453\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 1.1027 - sparse_categorical_accuracy: 0.7184 - val_loss: 1.1887 - val_sparse_categorical_accuracy: 0.7472\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 1.0021 - sparse_categorical_accuracy: 0.7284 - val_loss: 1.0801 - val_sparse_categorical_accuracy: 0.7621\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 15s 78ms/step - loss: 0.9612 - sparse_categorical_accuracy: 0.7378 - val_loss: 1.2532 - val_sparse_categorical_accuracy: 0.7617\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 0.9636 - sparse_categorical_accuracy: 0.7439 - val_loss: 1.1302 - val_sparse_categorical_accuracy: 0.7705\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 15s 79ms/step - loss: 0.8979 - sparse_categorical_accuracy: 0.7518 - val_loss: 1.2024 - val_sparse_categorical_accuracy: 0.7825\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 0.8709 - sparse_categorical_accuracy: 0.7606 - val_loss: 1.3121 - val_sparse_categorical_accuracy: 0.7920\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 14s 76ms/step - loss: 0.8665 - sparse_categorical_accuracy: 0.7680 - val_loss: 1.1460 - val_sparse_categorical_accuracy: 0.7856\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 14s 76ms/step - loss: 0.8332 - sparse_categorical_accuracy: 0.7672 - val_loss: 1.2435 - val_sparse_categorical_accuracy: 0.7911\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 0.8328 - sparse_categorical_accuracy: 0.7668 - val_loss: 1.4951 - val_sparse_categorical_accuracy: 0.7958\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 15s 78ms/step - loss: 0.8176 - sparse_categorical_accuracy: 0.7735 - val_loss: 1.2179 - val_sparse_categorical_accuracy: 0.7912\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 15s 77ms/step - loss: 0.8250 - sparse_categorical_accuracy: 0.7767 - val_loss: 1.0902 - val_sparse_categorical_accuracy: 0.7911\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 15s 78ms/step - loss: 0.8171 - sparse_categorical_accuracy: 0.7757 - val_loss: 1.0829 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 15s 81ms/step - loss: 0.8270 - sparse_categorical_accuracy: 0.7754 - val_loss: 1.1418 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 14s 75ms/step - loss: 0.8183 - sparse_categorical_accuracy: 0.7763 - val_loss: 1.0700 - val_sparse_categorical_accuracy: 0.7930\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.0829 - sparse_categorical_accuracy: 0.7979\n",
      "Test accuracy: 79.79%\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=1,callbacks=[early_stop])\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a242ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
