{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b7a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\lavra\\miniconda3\\envs\\tensorflow\\lib\\site-packages (0.16.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\lavra\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100dbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "AUTO=tf.data.AUTOTUNE\n",
    "learning_rate = 0.001\n",
    "batch_size = 265\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "\n",
    "\n",
    "\n",
    "# Load the train and test data splits\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Display shapes of train and test datasets\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n",
    "test_dataset=(tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .shuffle(1024)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4ca8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.02),\n",
    "        layers.RandomWidth(0.2),\n",
    "        layers.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272493ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder(backbone=keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
    "    )):\n",
    "    \n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = backbone(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad87d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b87d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95fd8c",
   "metadata": {},
   "source": [
    "## model definition with the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8919d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 64)   9472        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 16, 16, 64)  0           ['batch_normalization[0][0]',    \n",
      " da)                                                              'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 16, 16, 64)   0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 64)  256         ['re_lu[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 16, 16, 64)  0           ['batch_normalization_2[0][0]',  \n",
      " mbda)                                                            'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 16, 16, 64)   0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 64)  256         ['re_lu_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 64)   36928       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 16, 16, 64)  0           ['batch_normalization_4[0][0]',  \n",
      " mbda)                                                            'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 16, 16, 64)   0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 64)  256         ['re_lu_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 128)    73856       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 128)    8320        ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 128)    147584      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 8, 8, 128)   0           ['conv2d_7[0][0]',               \n",
      " mbda)                                                            'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 8, 8, 128)    0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 128)   512         ['re_lu_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 4, 4, 256)    295168      ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 4, 4, 256)    33024       ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 4, 4, 256)    590080      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 4, 4, 256)   0           ['conv2d_10[0][0]',              \n",
      " mbda)                                                            'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 4, 4, 256)    0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 4, 4, 256)   1024        ['re_lu_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 4, 4, 2048)   4720640     ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 4, 4, 2048)  8192        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['batch_normalization_11[0][0]'] \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,112,768\n",
      "Trainable params: 6,106,240\n",
      "Non-trainable params: 6,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def apply_resnet_block(x,downsample,conv_by_block):\n",
    "    \n",
    "    depth_input=x.shape[-1]\n",
    "    \n",
    "    \n",
    "    if downsample:\n",
    "        depth=depth_input*2\n",
    "        skiped=layers.Conv2D(depth,1,strides=(2,2),activation=None)(x)#linear projection\n",
    "        x=layers.Conv2D(depth,3,strides=(2,2), activation='relu',padding=\"same\")(x)\n",
    "        x=layers.BatchNormalization()(x)\n",
    "    else:\n",
    "        depth=depth_input\n",
    "        skiped=x\n",
    "        x=layers.Conv2D(depth,3, activation='relu',padding=\"same\")(x)\n",
    "        x=layers.BatchNormalization()(x)\n",
    "        \n",
    "    for i in range(1,conv_by_block-1):\n",
    "        x=layers.Conv2D(depth,3, activation='relu',padding=\"same\")(x)\n",
    "        x=layers.BatchNormalization()(x)\n",
    "    \n",
    "    x=layers.Conv2D(depth,3,padding=\"same\")(x)#don't apply activation to the last \n",
    "         \n",
    "    x=skiped+x\n",
    "    x=layers.ReLU()(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "   \n",
    "    return x\n",
    "\n",
    "def get_resnet_backbone(input_shape,hparams):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    assert hparams[\"conv_by_block\"]>=2\n",
    "    inputs=layers.Input((32,32,3))\n",
    "    x=layers.Conv2D(hparams[\"depth_first_convolution\"],7,strides=(2,2),activation='relu',padding=\"same\")(inputs)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    for block in range(1,hparams[\"number_of_block\"]+1):\n",
    "        x=apply_resnet_block(x,block in hparams[\"downsample_num\"],hparams[\"conv_by_block\"])\n",
    "       \n",
    "        \n",
    "    x=layers.Conv2D(hparams[\"output_dim\"],3, activation='relu',padding=\"same\")(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    if hparams[\"globalPoolingType\"]==\"Mean\":\n",
    "        \n",
    "        x=layers.GlobalAveragePooling2D()(x)\n",
    " \n",
    "    return tf.keras.Model(inputs,x)\n",
    "\n",
    "\n",
    "\n",
    "hparams_resnet={\"depth_first_convolution\":64,\n",
    "                \"output_dim\":2048,\n",
    "                \"number_of_block\":5,\n",
    "                \"downsample_num\":[4,5],\n",
    "                \"conv_by_block\":2,\n",
    "                \"globalPoolingType\":\"Mean\"\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resnet=get_resnet_backbone(input_shape,hparams_resnet)\n",
    "\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04610f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             6112775   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,166,993\n",
      "Trainable params: 7,160,458\n",
      "Non-trainable params: 6,535\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 111s 462ms/step - loss: 1.7198 - sparse_categorical_accuracy: 0.3969 - val_loss: 1.3962 - val_sparse_categorical_accuracy: 0.4901\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 44s 234ms/step - loss: 1.2610 - sparse_categorical_accuracy: 0.5491 - val_loss: 1.2939 - val_sparse_categorical_accuracy: 0.5762\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 39s 205ms/step - loss: 1.0575 - sparse_categorical_accuracy: 0.6230 - val_loss: 1.1574 - val_sparse_categorical_accuracy: 0.6291\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 40s 209ms/step - loss: 0.9283 - sparse_categorical_accuracy: 0.6745 - val_loss: 1.1045 - val_sparse_categorical_accuracy: 0.6608\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 37s 195ms/step - loss: 0.8293 - sparse_categorical_accuracy: 0.7103 - val_loss: 0.9470 - val_sparse_categorical_accuracy: 0.6910\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 37s 197ms/step - loss: 0.7549 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.9782 - val_sparse_categorical_accuracy: 0.6928\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.6921 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.9293 - val_sparse_categorical_accuracy: 0.7228\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.6484 - sparse_categorical_accuracy: 0.7763 - val_loss: 0.8464 - val_sparse_categorical_accuracy: 0.7292\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 37s 196ms/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7915 - val_loss: 0.9490 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 37s 196ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.7838\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 37s 195ms/step - loss: 0.5383 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.7734\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 39s 207ms/step - loss: 0.5104 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.7812\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 38s 200ms/step - loss: 0.4901 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.7839\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 38s 200ms/step - loss: 0.4625 - sparse_categorical_accuracy: 0.8398 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.7813\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 38s 199ms/step - loss: 0.4464 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.6287 - val_sparse_categorical_accuracy: 0.8030\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 36s 191ms/step - loss: 0.4344 - sparse_categorical_accuracy: 0.8494 - val_loss: 0.7159 - val_sparse_categorical_accuracy: 0.7961\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 37s 198ms/step - loss: 0.4070 - sparse_categorical_accuracy: 0.8597 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 37s 197ms/step - loss: 0.3932 - sparse_categorical_accuracy: 0.8646 - val_loss: 0.6158 - val_sparse_categorical_accuracy: 0.8106\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.3825 - sparse_categorical_accuracy: 0.8673 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.8183\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 37s 196ms/step - loss: 0.3670 - sparse_categorical_accuracy: 0.8722 - val_loss: 0.6112 - val_sparse_categorical_accuracy: 0.8233\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 37s 196ms/step - loss: 0.3495 - sparse_categorical_accuracy: 0.8797 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.8217\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.3424 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.5621 - val_sparse_categorical_accuracy: 0.8289\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 37s 196ms/step - loss: 0.3289 - sparse_categorical_accuracy: 0.8840 - val_loss: 0.6069 - val_sparse_categorical_accuracy: 0.8195\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.3179 - sparse_categorical_accuracy: 0.8899 - val_loss: 0.5858 - val_sparse_categorical_accuracy: 0.8267\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 37s 196ms/step - loss: 0.3094 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.8296\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 36s 193ms/step - loss: 0.2934 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.8338\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 35s 188ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.8973 - val_loss: 0.5151 - val_sparse_categorical_accuracy: 0.8465\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.8207\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 36s 190ms/step - loss: 0.2741 - sparse_categorical_accuracy: 0.9055 - val_loss: 0.6166 - val_sparse_categorical_accuracy: 0.8353\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 36s 191ms/step - loss: 0.2602 - sparse_categorical_accuracy: 0.9073 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.8340\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 37s 195ms/step - loss: 0.2557 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.8457\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 37s 194ms/step - loss: 0.2495 - sparse_categorical_accuracy: 0.9127 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.8452\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 37s 195ms/step - loss: 0.2482 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.5718 - val_sparse_categorical_accuracy: 0.8466\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 37s 194ms/step - loss: 0.2357 - sparse_categorical_accuracy: 0.9185 - val_loss: 0.5522 - val_sparse_categorical_accuracy: 0.8497\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.2262 - sparse_categorical_accuracy: 0.9202 - val_loss: 0.6087 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 37s 193ms/step - loss: 0.2258 - sparse_categorical_accuracy: 0.9214 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.8411\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 36s 191ms/step - loss: 0.2189 - sparse_categorical_accuracy: 0.9235 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.8396\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 37s 196ms/step - loss: 0.2101 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.8373\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 37s 197ms/step - loss: 0.2050 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.8607\n",
      "Epoch 40/50\n",
      "189/189 [==============================] - 36s 189ms/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.5524 - val_sparse_categorical_accuracy: 0.8495\n",
      "Epoch 41/50\n",
      "189/189 [==============================] - 37s 195ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9320 - val_loss: 0.5964 - val_sparse_categorical_accuracy: 0.8468\n",
      "Epoch 42/50\n",
      "189/189 [==============================] - 36s 190ms/step - loss: 0.1959 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.5982 - val_sparse_categorical_accuracy: 0.8470\n",
      "Epoch 43/50\n",
      "189/189 [==============================] - 37s 195ms/step - loss: 0.1880 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.5629 - val_sparse_categorical_accuracy: 0.8521\n",
      "Epoch 44/50\n",
      "189/189 [==============================] - 37s 194ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9366 - val_loss: 0.6006 - val_sparse_categorical_accuracy: 0.8478\n",
      "Epoch 45/50\n",
      "189/189 [==============================] - 36s 188ms/step - loss: 0.1810 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.6280 - val_sparse_categorical_accuracy: 0.8491\n",
      "Epoch 46/50\n",
      "189/189 [==============================] - 37s 193ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.6300 - val_sparse_categorical_accuracy: 0.8539\n",
      "Epoch 47/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 0.1734 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.8624\n",
      "Epoch 48/50\n",
      "189/189 [==============================] - 37s 197ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9442 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 49/50\n",
      "189/189 [==============================] - 37s 194ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.8518\n",
      "Epoch 50/50\n",
      "189/189 [==============================] - 35s 187ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.8503\n",
      "313/313 [==============================] - 8s 22ms/step - loss: 0.6346 - sparse_categorical_accuracy: 0.8503\n",
      "Test accuracy: 85.03%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"sparse_categorical_accuracy\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "encoder = create_encoder(resnet)\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary(expand_nested=False)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0edd4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             6112775   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,375,047\n",
      "Trainable params: 6,368,512\n",
      "Non-trainable params: 6,535\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 118s 486ms/step - loss: 6.0559\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 38s 202ms/step - loss: 5.4287\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 35s 186ms/step - loss: 5.1697\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 36s 192ms/step - loss: 5.0757\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 4.9794\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 4.8853\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 36s 193ms/step - loss: 4.7946\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 35s 186ms/step - loss: 4.7077\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 35s 182ms/step - loss: 4.6235\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 35s 186ms/step - loss: 4.5433\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 4.4808\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 4.4087\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 4.3619\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 35s 185ms/step - loss: 4.3148\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 35s 184ms/step - loss: 4.2608\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 4.2124\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 32s 171ms/step - loss: 4.1779\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 35s 183ms/step - loss: 4.1375\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 33s 174ms/step - loss: 4.1169\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 4.0796\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 4.0507\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 4.0237\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 3.9974\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 3.9872\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 33s 174ms/step - loss: 3.9439\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 34s 182ms/step - loss: 3.9387\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 3.9105\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 33s 174ms/step - loss: 3.8948\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 3.8578\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 3.8480\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 3.8333\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 3.8081\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 3.7998\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 34s 178ms/step - loss: 3.7803\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 34s 181ms/step - loss: 3.7822\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 33s 173ms/step - loss: 3.7845\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 3.7468\n",
      "Epoch 38/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 3.7244\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 33s 174ms/step - loss: 3.7184\n",
      "Epoch 40/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 3.6957\n",
      "Epoch 41/50\n",
      "189/189 [==============================] - 32s 172ms/step - loss: 3.6734\n",
      "Epoch 42/50\n",
      "189/189 [==============================] - 33s 173ms/step - loss: 3.6730\n",
      "Epoch 43/50\n",
      "189/189 [==============================] - 34s 179ms/step - loss: 3.6501\n",
      "Epoch 44/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 3.6440\n",
      "Epoch 45/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 3.6563\n",
      "Epoch 46/50\n",
      "189/189 [==============================] - 35s 183ms/step - loss: 3.6254\n",
      "Epoch 47/50\n",
      "189/189 [==============================] - 34s 180ms/step - loss: 3.6104\n",
      "Epoch 48/50\n",
      "189/189 [==============================] - 33s 176ms/step - loss: 3.6072\n",
      "Epoch 49/50\n",
      "189/189 [==============================] - 33s 177ms/step - loss: 3.5951\n",
      "Epoch 50/50\n",
      "189/189 [==============================] - 33s 175ms/step - loss: 3.5760\n"
     ]
    }
   ],
   "source": [
    "early_stop_unsup=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "learning_rate=0.001\n",
    "resnet=get_resnet_backbone(input_shape,hparams_resnet)\n",
    "\n",
    "encoder = create_encoder(resnet)\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(\n",
    "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop_unsup]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06bc6f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 98s 427ms/step - loss: 0.4369 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.8594\n",
      "Epoch 1/50\n",
      "189/189 [==============================] - 80s 385ms/step - loss: 0.3051 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.8646\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 73s 386ms/step - loss: 0.2423 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.5070 - val_sparse_categorical_accuracy: 0.8627\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 72s 383ms/step - loss: 0.2087 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.5032 - val_sparse_categorical_accuracy: 0.8645\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 73s 389ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9346 - val_loss: 0.5002 - val_sparse_categorical_accuracy: 0.8635\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 69s 366ms/step - loss: 0.2049 - sparse_categorical_accuracy: 0.9366 - val_loss: 0.4930 - val_sparse_categorical_accuracy: 0.8665\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 68s 361ms/step - loss: 0.1945 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.8648\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 68s 361ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.8639\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 70s 374ms/step - loss: 0.1922 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.4939 - val_sparse_categorical_accuracy: 0.8638\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 70s 370ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.5080 - val_sparse_categorical_accuracy: 0.8614\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 67s 354ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.4854 - val_sparse_categorical_accuracy: 0.8648\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 68s 359ms/step - loss: 0.1960 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.4893 - val_sparse_categorical_accuracy: 0.8643\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 72s 383ms/step - loss: 0.1777 - sparse_categorical_accuracy: 0.9424 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8656\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 67s 356ms/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.5046 - val_sparse_categorical_accuracy: 0.8642\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 67s 356ms/step - loss: 0.1830 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.4940 - val_sparse_categorical_accuracy: 0.8627\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 69s 365ms/step - loss: 0.1743 - sparse_categorical_accuracy: 0.9422 - val_loss: 0.4896 - val_sparse_categorical_accuracy: 0.8655\n",
      "313/313 [==============================] - 41s 24ms/step - loss: 0.4852 - sparse_categorical_accuracy: 0.8656\n",
      "Test accuracy: 86.56%\n"
     ]
    }
   ],
   "source": [
    "early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"sparse_categorical_accuracy\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=1,callbacks=[early_stop])\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train,validation_data=test_dataset, batch_size=batch_size, epochs=num_epochs,callbacks=[early_stop])\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
